
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine learning: Introduction &#8212; SCMA248 Introduction to Data Science</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">SCMA248 Introduction to Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to SCMA248 Introduction to Data Science
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter1_Introduction_to_Data_Science.html">
   1. Introduction to Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter2_Python_Basics.html">
   2. Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter3_Data_Preparation.html">
   3. Data Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter4_Data_Visualization.html">
   6. Data Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter5_Practical_Statistics.html">
   7. Practical Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter6_Regression.html">
   8. Regression Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter7_Introduction_Machine_Learning.html">
   9. Machine learning: Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Chapter8_Unsupervised_Learning.html">
   10. Unsupervised Machine Learning: K-means Clustering
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Chapter7_Introduction_Machine_Learning-Copy1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FChapter7_Introduction_Machine_Learning-Copy1.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/Chapter7_Introduction_Machine_Learning-Copy1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning">
   What Is Machine Learning?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-models-of-data">
     Building models of data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-of-machine-learning">
   Applications of Machine learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#categories-of-machine-learning">
   Categories of Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supervised-learning">
     Supervised learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#classification-problems-more-examples-below">
       Classification problems (more examples below)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regression-problem-discussed-in-our-last-chatpter">
       Regression problem (discussed in our last chatpter)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unsupervised-learning-more-details-in-the-next-chapter">
     Unsupervised learning (more details in the next chapter)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supervised-vs-unsupervised-learning-image-from-researchgate">
     Supervised vs Unsupervised Learning: image from researchgate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#various-classification-regression-and-clustering-algorithms-image-from-scikit-learn">
     Various classification, regression and clustering algorithms: image from scikit-learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-basics-with-the-k-nearest-neighbors-algorithm">
   Machine Learning Basics with the K-Nearest Neighbors Algorithm
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-nearest-neighbours-can-be-summarized-as-follows">
     K-nearest neighbours can be summarized as follows:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn-algorithm-s-theory">
     KNN algorithm’s theory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-on-knn-classifiers-image-from-researchgate">
     Example on KNN classifiers: image from Researchgate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-https-raw-githubusercontent-com-susanli2016-machine-learning-with-python-master-fruit-data-with-colors-txt">
     Dataset: https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#our-goals">
       Our goals
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exploratory-data-analysis">
       Exploratory data analysis
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#what-we-observe-from-the-figures">
       What we observe from the figures?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#preprocessing-train-test-split">
       Preprocessing: Train Test Split.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#training-and-predictions">
       Training and Predictions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#train-the-classifier-fit-the-estimator-using-the-training-data">
       Train the classifier (fit the estimator) using the training data¶
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#estimate-the-accuracy-of-the-classifier-on-future-data-using-the-test-data">
       Estimate the accuracy of the classifier on future data, using the test data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#use-the-trained-knn-classifier-model-to-classify-new-previously-unseen-objects">
       Use the trained KNN classifier model to classify new, previously unseen objects
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#calculating-the-agorithm-accuracy">
       Calculating the agorithm accuracy
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparison-of-the-observed-and-predicted-values-from-both-training-and-test-data-sets">
       Comparison of the observed and predicted values from both training and test data sets
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#visualize-the-decision-regions-of-a-classifier">
       Visualize the decision regions of a classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#decision-regions-for-two-features-height-and-mass">
       Decision regions for two features, height and mass.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#decision-regions-for-two-features-height-and-width">
       Decision regions for two features, height and width.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#applying-knn-classfication-with-only-two-features">
       Applying KNN classfication with only two features
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#width-mass-visualization">
       Width-Mass visualization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#width-height-visualization">
       Width-height visualization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#visualize-from-scratch-the-decision-regions-of-a-classifier">
       Visualize (from scratch) the decision regions of a classifier
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation-metrics-in-machine-learning">
   Model Evaluation Metrics in Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-we-figure-out-which-algorithm-is-the-most-effective">
     How can we figure out which algorithm is the most effective?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regression-related-metrics">
       Regression Related Metrics
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#classification-metrics">
       Classification Metrics
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling">
   Scaling
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning-introduction">
<h1>Machine learning: Introduction<a class="headerlink" href="#machine-learning-introduction" title="Permalink to this headline">¶</a></h1>
<p><strong>Machine learning</strong> is clearly one of the most powerful and significant technologies in the world today. And more importantly, we have yet to fully realize its potential. It will undoubtedly continue to make headlines for the foreseeable future.</p>
<p>Machine learning is <strong>a technique for transforming data into knowledge</strong>. In the last 50 years, there has been a data explosion. This vast amount of data is worthless until we analyze it and uncover the underlying patterns.</p>
<p>Machine learning techniques are being used to <strong>discover useful underlying patterns in complex data</strong> that would otherwise be difficult to find. Hidden patterns and problem knowledge can be used to predict future events and make a variety of complex decisions.</p>
<section id="what-is-machine-learning">
<h2>What Is Machine Learning?<a class="headerlink" href="#what-is-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning is the study of computer algorithms that can learn and develop on their own with experience and data.</p>
<p>It is considered to be a component of <strong>artificial intelligence</strong>.</p>
<p>Machine learning algorithms create a model based on <strong>training data</strong> to make predictions or decisions without having to be explicitly programmed to do so.</p>
<section id="building-models-of-data">
<h3>Building models of data<a class="headerlink" href="#building-models-of-data" title="Permalink to this headline">¶</a></h3>
<p>It makes more sense to think of machine learning as a means of <strong>building models of data</strong>.</p>
<p>Machine learning is fundamentally about building mathematical models that facilitate the understanding of data.</p>
<p>If we provide these models with <strong>tunable parameters</strong> that can be adapted to the observed data, we can call the program <strong>“learning” from the data</strong>.</p>
<p>These models can be used to <strong>predict and understand features of newly observed data</strong> after fitting them to previously seen data.</p>
<p><strong>Categories of Machine Learning</strong>: image from ceralytics
<img alt="Categories of Machine Learning: from ceralytics" src="https://www.ceralytics.com/wp-content/uploads/2019/08/machine-learning.jpg" /></p>
</section>
</section>
<section id="applications-of-machine-learning">
<h2>Applications of Machine learning<a class="headerlink" href="#applications-of-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning tasks can be used for a variety of things. Here are some examples of traditional machine learning tasks:</p>
<ol class="simple">
<li><p><strong>Recommendation systems</strong></p></li>
</ol>
<p><img alt="Netflix recommendation system: from medium" src="https://miro.medium.com/max/1400/1*QKQA8ylu1lCtOkJaa_gGaw.png" /></p>
<p>We come across a variety of online recommendation engines and methods. Many major platforms, such as Amazon, Netflix, and others, use these technologies. These recommendation engines use a machine learning system that takes into account user search results and preferences.</p>
<p>The algorithm uses this information to make similar recommendations the next time you open the platform.</p>
<p>You will receive notifications about new programs on Netflix. Netflix’s algorithm checks the entire viewing history of its subscribers. It uses this information to suggest new series based on the preferences of its millions of active viewers.</p>
<p>The same recommendation engine can also be used to create ads. Take Amazon, for example. Let us say you go to Amazon to store or just search for something. Amazon’s machine learning technology analyzes the user’s search results and then generates ads as recommendations.</p>
<ol class="simple">
<li><p><strong>Machine learning for Illness Prediction Healthcare use cases in healthcare</strong>.</p></li>
</ol>
<p><img alt="Building Heart disease classifier using K-NN algorithm: image from https://cdn-images-1.medium.com/max/800/1*tGeiO5zee6exueRC8iBuaQ.jpeg" src="https://cdn-images-1.medium.com/max/800/1*tGeiO5zee6exueRC8iBuaQ.jpeg" /></p>
<p>Doctors can warn patients ahead of time if they can predict a disease. They can even tell if a disease is dangerous or not, which is quite remarkable. But even though using ML is not an easy task, it can be of great benefit.</p>
<p>In this case, the ML algorithm first looks for symptoms on the patient’s body. It would use abnormal body functions as input, train the algorithm, and then make a prediction based on that. Since there are hundreds of diseases and twice as many symptoms, it may take some time to get the results.</p>
<ol class="simple">
<li><p><strong>Credit score - banking machine learning examples</strong>.</p></li>
</ol>
<p>It can be difficult to determine whether a bank customer is creditworthy. This is critical because whether or not the bank will grant you a loan depends on it.</p>
<p>Traditional credit card companies only check to see if the card is current and perform a history check. If the cardholder does not have a card history, the assessment becomes more difficult. For this, there are a number of machine learning algorithms that take into account the user’s financial situation, previous credit repayments, debts and so on.</p>
<p>Due to a large number of defaulters, banks have already suffered significant financial losses. To limit these types of losses, we need an effective machine learning system that can prevent any of these scenarios from occurring. This would save banks a lot of money and allow them to provide more services to real consumers.</p>
</section>
<section id="categories-of-machine-learning">
<h2>Categories of Machine Learning<a class="headerlink" href="#categories-of-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning can be divided into two forms at the most basic level: supervised learning and unsupervised learning.</p>
<section id="supervised-learning">
<h3>Supervised learning<a class="headerlink" href="#supervised-learning" title="Permalink to this headline">¶</a></h3>
<p>Supervised learning involves determining how to model the relationship between measured data features and a label associated with the data; once this model is determined, it can be used to apply labels to new, unknown data. This is further divided into <strong>classification</strong> and <strong>regression</strong> tasks, where the <strong>labels in classification are discrete categories</strong> and the <strong>labels in regression are continuous values</strong>.</p>
<section id="classification-problems-more-examples-below">
<h4>Classification problems (more examples below)<a class="headerlink" href="#classification-problems-more-examples-below" title="Permalink to this headline">¶</a></h4>
<p>The output of a classification task is a discrete value. “Likes adding sugar to coffee” and “does not like adding sugar to coffee,” for example, are discrete. There is no such thing as a middle ground. This is similar to teaching a child to recognize different types of animals, whether they are pets or not.</p>
<p>The output (label) of a classification method is typically represented as an integer number such as 1, -1, or 0. These figures are solely symbolic in this situation. Mathematical operations should not be performed with them because this would be pointless. Consider this for a moment. What is the difference between “Likes adding sugar to coffee” and “does not like adding sugar to coffee”? Exactly. We won’t be able to add them, therefore we won’t.</p>
</section>
<section id="regression-problem-discussed-in-our-last-chatpter">
<h4>Regression problem (discussed in our last chatpter)<a class="headerlink" href="#regression-problem-discussed-in-our-last-chatpter" title="Permalink to this headline">¶</a></h4>
<p>The outcome of a regression problem is a real number (a number with a decimal point). We could, for example, use the height and weight information to estimate someone’s weight based on their height.</p>
<p>The data for a regression analysis will like the data in insurance data set. A <strong>dependent variable</strong> (or set of independent variables) and an <strong>independent variable</strong> (the thing we are trying to guess given our independent variables) are both present.</p>
<p>We could state that height is the independent variable and weight is the dependent variable, for example.
In addition, each row in the dataset is commonly referred to as an <strong>example, observation, or data point</strong>, but each column (without the <strong>label/dependent variable</strong>) is commonly referred to as a <strong>predictor, independent variable, or feature</strong>.</p>
<p><img alt="Supervised learning: image from medium" src="https://miro.medium.com/max/1400/1*589X2eXJJkatGRG-z-s_oA.png" /></p>
</section>
</section>
<section id="unsupervised-learning-more-details-in-the-next-chapter">
<h3>Unsupervised learning (more details in the next chapter)<a class="headerlink" href="#unsupervised-learning-more-details-in-the-next-chapter" title="Permalink to this headline">¶</a></h3>
<p>Unsupervised learning, sometimes known as “letting the dataset speak for itself,” models the features of a dataset without reference to a label. Clustering and dimensionality reduction are among the tasks these models perform.</p>
<p><strong>Clustering methods</strong> find unique groups of data, while <strong>dimensionality reduction</strong> algorithms look for more concise representations.</p>
</section>
<section id="supervised-vs-unsupervised-learning-image-from-researchgate">
<h3>Supervised vs Unsupervised Learning: image from researchgate<a class="headerlink" href="#supervised-vs-unsupervised-learning-image-from-researchgate" title="Permalink to this headline">¶</a></h3>
<p><img alt="Supervised vs Unsupervised Learning: image from researchgate" src="https://www.researchgate.net/publication/329533120/figure/fig1/AS:702267594399761&#64;1544445050584/Supervised-learning-and-unsupervised-learning-Supervised-learning-uses-annotation_W640.jpg" /></p>
</section>
<section id="various-classification-regression-and-clustering-algorithms-image-from-scikit-learn">
<h3>Various classification, regression and clustering algorithms: image from scikit-learn<a class="headerlink" href="#various-classification-regression-and-clustering-algorithms-image-from-scikit-learn" title="Permalink to this headline">¶</a></h3>
<p><img alt="Various classification, regression and clustering algorithms: image from scikit-learn" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Scikit-learn_machine_learning_decision_tree.png/1024px-Scikit-learn_machine_learning_decision_tree.png" /></p>
</section>
</section>
<section id="machine-learning-basics-with-the-k-nearest-neighbors-algorithm">
<h2>Machine Learning Basics with the K-Nearest Neighbors Algorithm<a class="headerlink" href="#machine-learning-basics-with-the-k-nearest-neighbors-algorithm" title="Permalink to this headline">¶</a></h2>
<p>We will learn what <strong>K-nearest neighbours (KNN)</strong> is, how it works, and how to find the right k value. We will utilize the well-known Python library sklearn to demonstrate how to use KNN.</p>
<section id="k-nearest-neighbours-can-be-summarized-as-follows">
<h3>K-nearest neighbours can be summarized as follows:<a class="headerlink" href="#k-nearest-neighbours-can-be-summarized-as-follows" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>K- Nearest Neighbors is a <strong>supervised machine learning</strong> approach since the target variable is known,</p></li>
<li><p>It is <strong>non-parametric</strong>, since no assumptions are made about the underlying data distribution pattern.</p></li>
<li><p>It predicts the cluster into which the new point will fall based on feature similarity.</p></li>
</ul>
<p>Both classification and regression prediction problems can be solved with KNN. However, since most analytical problems require making a decision, it is more commonly used in classification problems .</p>
</section>
<section id="knn-algorithm-s-theory">
<h3>KNN algorithm’s theory<a class="headerlink" href="#knn-algorithm-s-theory" title="Permalink to this headline">¶</a></h3>
<p>The KNN algorithm’s concept is one of the most straightforward of all the supervised machine learning algorithms.</p>
<p>It simply calculates the distance between a new data point and all previous data points in the training set.</p>
<p>Any form of distance can be used, such as</p>
<ul class="simple">
<li><p>Euclidean or</p></li>
<li><p>Manhattan distances.</p></li>
</ul>
<p>The K-nearest data points are then chosen, where K can be any integer. Finally, the data point is assigned to the class that contains the majority of the K data points.</p>
<p>Note that the Manhattan distance, <span class="math notranslate nohighlight">\({\displaystyle d_{1}}\)</span>, between two vectors <span class="math notranslate nohighlight">\({\displaystyle \mathbf {p} ,\mathbf {q} }\)</span>  in an n-dimensional real vector space with fixed Cartesian coordinate system is defined as</p>
<div class="math notranslate nohighlight">
\[d_{1}(\mathbf {p} ,\mathbf {q} )=\|\mathbf {p} -\mathbf {q} \|_{1}=\sum _{i=1}^{n}|p_{i}-q_{i}|,\]</div>
<p>where <span class="math notranslate nohighlight">\({\displaystyle (\mathbf {p} ,\mathbf {q} )}\)</span> are vectors</p>
<div class="math notranslate nohighlight">
\[{\displaystyle \mathbf {p} =(p_{1},p_{2},\dots ,p_{n}){\text{ and }}\mathbf {q} =(q_{1},q_{2},\dots ,q_{n})\,}.\]</div>
</section>
<section id="example-on-knn-classifiers-image-from-researchgate">
<h3>Example on KNN classifiers: image from Researchgate<a class="headerlink" href="#example-on-knn-classifiers-image-from-researchgate" title="Permalink to this headline">¶</a></h3>
<p><img alt="Example on KNN classifiers: image from Researchgate" src="https://www.researchgate.net/profile/Mohammed-Badawy/publication/331424423/figure/fig1/AS:732056359297024&#64;1551547245072/Example-on-KNN-classifier_W640.jpg" /></p>
<p>Our goal in this diagram is to identify a new data point with the symbol ‘Pt’ into one of three categories: “A,” “B,” or “C.”</p>
<p>Assume that K is equal to 7. The KNN algorithm begins by computing the distance between point ‘Pt’ and all of the other points. The 7 closest points with the shortest distance to point ‘Pt’ are then found. This is depicted in the diagram below. Arrows have been used to denote the seven closest points.</p>
<p>The KNN algorithm’s final step is to assign a new point to the class that contains the majority of the seven closest points. Three of the seven closest points belong to the class “B,” while two of the seven belongs to the classes “A” and “C”. Therefore the new data point will be classified as “B”.</p>
</section>
<section id="dataset-https-raw-githubusercontent-com-susanli2016-machine-learning-with-python-master-fruit-data-with-colors-txt">
<h3>Dataset: <a class="reference external" href="https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt">https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt</a><a class="headerlink" href="#dataset-https-raw-githubusercontent-com-susanli2016-machine-learning-with-python-master-fruit-data-with-colors-txt" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">var</span><span class="o">/</span><span class="n">folders</span><span class="o">/</span><span class="n">kl</span><span class="o">/</span><span class="n">h_r05n_j76n32kt0dwy7kynw0000gn</span><span class="o">/</span><span class="n">T</span><span class="o">/</span><span class="n">ipykernel_5521</span><span class="o">/</span><span class="mf">278679566.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;matplotlib&#39;</span><span class="p">,</span> <span class="s1">&#39;inline&#39;</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;seaborn&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span> <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">module</span> <span class="o">=</span> <span class="s2">&quot;matplotlib\..*&quot;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will be using the fruit_data_with_colors dataset, avalable here at github page, <a class="reference external" href="https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt">https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt</a>.</p>
<p>The mass, height, and width of a variety of oranges, lemons, and apples are included in the file. The heights were taken along the fruit’s core. The widths were measured perpendicular to the height at their widest point.</p>
<section id="our-goals">
<h4>Our goals<a class="headerlink" href="#our-goals" title="Permalink to this headline">¶</a></h4>
<p>To predict the appropriate fruit label, we’ll use the mass, width, and height of the fruit as our feature points (target value).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
    
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fruit_label</th>
      <th>fruit_name</th>
      <th>fruit_subtype</th>
      <th>mass</th>
      <th>width</th>
      <th>height</th>
      <th>color_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>192</td>
      <td>8.4</td>
      <td>7.3</td>
      <td>0.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>180</td>
      <td>8.0</td>
      <td>6.8</td>
      <td>0.59</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>176</td>
      <td>7.4</td>
      <td>7.2</td>
      <td>0.60</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>86</td>
      <td>6.2</td>
      <td>4.7</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>84</td>
      <td>6.0</td>
      <td>4.6</td>
      <td>0.79</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 59 entries, 0 to 58
Data columns (total 7 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   fruit_label    59 non-null     int64  
 1   fruit_name     59 non-null     object 
 2   fruit_subtype  59 non-null     object 
 3   mass           59 non-null     int64  
 4   width          59 non-null     float64
 5   height         59 non-null     float64
 6   color_score    59 non-null     float64
dtypes: float64(3), int64(2), object(2)
memory usage: 3.4+ KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()[</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fruit_label
1    19
2     5
3    19
4    16
Name: fruit_name, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Fruit_label Count&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;Fruit_label Count&#39;}, xlabel=&#39;fruit_name&#39;, ylabel=&#39;count&#39;&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_21_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_21_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fruit_label</th>
      <th>fruit_name</th>
      <th>fruit_subtype</th>
      <th>mass</th>
      <th>width</th>
      <th>height</th>
      <th>color_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>192</td>
      <td>8.4</td>
      <td>7.3</td>
      <td>0.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>180</td>
      <td>8.0</td>
      <td>6.8</td>
      <td>0.59</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>176</td>
      <td>7.4</td>
      <td>7.2</td>
      <td>0.60</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>86</td>
      <td>6.2</td>
      <td>4.7</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>84</td>
      <td>6.0</td>
      <td>4.6</td>
      <td>0.79</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">aes</span><span class="p">(</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">,</span><span class="n">fill</span> <span class="o">=</span> <span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">geom_bar</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">scale_fill_manual</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;olivedrab&#39;</span><span class="p">,</span> <span class="s1">&#39;gold&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">])</span>

<span class="p">)</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_23_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_23_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (306177621)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check whether there are any missing values.</span>

<span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fruit_label      0
fruit_name       0
fruit_subtype    0
mass             0
width            0
height           0
color_score      0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">fruit_label</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">fruit_name</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 2 3 4]
[&#39;apple&#39; &#39;mandarin&#39; &#39;orange&#39; &#39;lemon&#39;]
</pre></div>
</div>
</div>
</div>
<p>To make the results easier to understand, we first establish a mapping from fruit label value to fruit name.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a mapping from a mapping from fruit label value to fruit name</span>
<span class="n">lookup_fruit_name</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">fruit_label</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span> <span class="n">df</span><span class="o">.</span><span class="n">fruit_name</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
<span class="n">lookup_fruit_name</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{1: &#39;apple&#39;, 2: &#39;mandarin&#39;, 3: &#39;orange&#39;, 4: &#39;lemon&#39;}
</pre></div>
</div>
</div>
</div>
</section>
<section id="exploratory-data-analysis">
<h4>Exploratory data analysis<a class="headerlink" href="#exploratory-data-analysis" title="Permalink to this headline">¶</a></h4>
<p>It is now time to experiment with the data and make some visualizations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">,</span><span class="s1">&#39;mass&#39;</span><span class="p">,</span><span class="s1">&#39;width&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]],</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x124457d50&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_29_1.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_29_1.png" />
</div>
</div>
</section>
<section id="what-we-observe-from-the-figures">
<h4>What we observe from the figures?<a class="headerlink" href="#what-we-observe-from-the-figures" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p>Mandarin has both lower mass and height. It also has the lower average widths.</p></li>
<li><p>Orange has higher average masses and widths.</p></li>
<li><p>There is a <strong>clear separation</strong> of lemon from the other both width-height plot and height-mass plot.</p></li>
<li><p>What else can we observe from the figures?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()[[</span><span class="s1">&#39;mass&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">mass</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>fruit_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>apple</th>
      <td>19.0</td>
      <td>165.052632</td>
      <td>11.969747</td>
      <td>140.0</td>
      <td>156.0</td>
      <td>164.0</td>
      <td>172.0</td>
      <td>192.0</td>
    </tr>
    <tr>
      <th>lemon</th>
      <td>16.0</td>
      <td>150.000000</td>
      <td>37.487776</td>
      <td>116.0</td>
      <td>117.5</td>
      <td>131.0</td>
      <td>188.0</td>
      <td>216.0</td>
    </tr>
    <tr>
      <th>mandarin</th>
      <td>5.0</td>
      <td>81.200000</td>
      <td>3.898718</td>
      <td>76.0</td>
      <td>80.0</td>
      <td>80.0</td>
      <td>84.0</td>
      <td>86.0</td>
    </tr>
    <tr>
      <th>orange</th>
      <td>19.0</td>
      <td>193.789474</td>
      <td>73.635422</td>
      <td>140.0</td>
      <td>154.0</td>
      <td>160.0</td>
      <td>197.0</td>
      <td>362.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()[[</span><span class="s1">&#39;height&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">height</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>fruit_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>apple</th>
      <td>19.0</td>
      <td>7.342105</td>
      <td>0.291196</td>
      <td>6.8</td>
      <td>7.1</td>
      <td>7.3</td>
      <td>7.55</td>
      <td>7.9</td>
    </tr>
    <tr>
      <th>lemon</th>
      <td>16.0</td>
      <td>8.856250</td>
      <td>0.997977</td>
      <td>7.5</td>
      <td>8.1</td>
      <td>8.5</td>
      <td>9.80</td>
      <td>10.5</td>
    </tr>
    <tr>
      <th>mandarin</th>
      <td>5.0</td>
      <td>4.380000</td>
      <td>0.277489</td>
      <td>4.0</td>
      <td>4.3</td>
      <td>4.3</td>
      <td>4.60</td>
      <td>4.7</td>
    </tr>
    <tr>
      <th>orange</th>
      <td>19.0</td>
      <td>7.936842</td>
      <td>0.769712</td>
      <td>7.0</td>
      <td>7.4</td>
      <td>7.8</td>
      <td>8.15</td>
      <td>9.4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()[[</span><span class="s1">&#39;width&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">width</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>fruit_name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>apple</th>
      <td>19.0</td>
      <td>7.457895</td>
      <td>0.345311</td>
      <td>6.9</td>
      <td>7.3</td>
      <td>7.4</td>
      <td>7.600</td>
      <td>8.4</td>
    </tr>
    <tr>
      <th>lemon</th>
      <td>16.0</td>
      <td>6.512500</td>
      <td>0.624900</td>
      <td>5.8</td>
      <td>6.0</td>
      <td>6.2</td>
      <td>7.225</td>
      <td>7.3</td>
    </tr>
    <tr>
      <th>mandarin</th>
      <td>5.0</td>
      <td>5.940000</td>
      <td>0.167332</td>
      <td>5.8</td>
      <td>5.8</td>
      <td>5.9</td>
      <td>6.000</td>
      <td>6.2</td>
    </tr>
    <tr>
      <th>orange</th>
      <td>19.0</td>
      <td>7.557895</td>
      <td>0.813986</td>
      <td>6.7</td>
      <td>7.1</td>
      <td>7.2</td>
      <td>7.600</td>
      <td>9.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="preprocessing-train-test-split">
<h4>Preprocessing: Train Test Split.<a class="headerlink" href="#preprocessing-train-test-split" title="Permalink to this headline">¶</a></h4>
<p>Because training and testing on the same data is inefficient, we partition the data into two sets: <strong>training and testing</strong>.</p>
<p>To split the data, we use the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> function.</p>
<p>The split percentage is determined by the optional parameter <code class="docutils literal notranslate"><span class="pre">test_size.</span></code> The default values are 75/25% train and test data.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">state</span></code> parameter ensures that the data is split in the same way each time the program is executed.</p>
<p>Because we are training and testing on distinct sets of data, the testing accuracy will be a better indication of how well the model will perform on new data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">,</span> <span class="s1">&#39;mass&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#shape of train and test data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(44, 3)
(15, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#shape of new y objects</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(44,)
(15,)
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-and-predictions">
<h4>Training and Predictions<a class="headerlink" href="#training-and-predictions" title="Permalink to this headline">¶</a></h4>
<p>Scikit-learn is divided into modules so that we may quickly import the classes we need.</p>
<p>Import the <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifer</span></code> class from the <code class="docutils literal notranslate"><span class="pre">neighbors</span></code> module.</p>
<p>Instantiate the estimator (a model in scikit-learn is referred to as a <strong>estimator</strong>). Because their major function is to estimate unknown quantities, we refer to the model as an estimator.</p>
<p>In our example, we have generated an instance (<code class="docutils literal notranslate"><span class="pre">knn</span></code>) of the class <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifer</span></code>, which means we have constructed an object called ‘knn’ that knows how to perform KNN classification once the data is provided.</p>
<p>The <strong>tuning parameter/hyper parameter</strong> (k) is the parameter <code class="docutils literal notranslate"><span class="pre">n_</span> <span class="pre">neighbors</span></code>. All other parameters are set to default.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method is used to train the model using training data (X train,y train), while the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method is used to test the model using testing data (X test).</p>
<p>In this example, we take <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> or k = 5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-classifier-fit-the-estimator-using-the-training-data">
<h4>Train the classifier (fit the estimator) using the training data¶<a class="headerlink" href="#train-the-classifier-fit-the-estimator-using-the-training-data" title="Permalink to this headline">¶</a></h4>
<p>We then train the classifier by passing the training set data in <strong>X_train</strong> and the labels in <strong>y_train</strong> to the classifier’s fit method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNeighborsClassifier()
</pre></div>
</div>
</div>
</div>
</section>
<section id="estimate-the-accuracy-of-the-classifier-on-future-data-using-the-test-data">
<h4>Estimate the accuracy of the classifier on future data, using the test data<a class="headerlink" href="#estimate-the-accuracy-of-the-classifier-on-future-data-using-the-test-data" title="Permalink to this headline">¶</a></h4>
<p>Remember that the KNN classifier has not seen any of the fruits in the <strong>test set</strong> during the training phase.</p>
<p>To do this, we use the score method for the classifier object.
This takes the points in the test set as input and calculates the <strong>accuracy</strong>.</p>
<p>The <strong>accuracy</strong> is defined as the proportion of points in the test set whose true label was correctly predicted by the classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy:&#39;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.5333333333333333
</pre></div>
</div>
</div>
</div>
<p>We obtain a classficiation rate of 53.3%, considered as good accuracy.</p>
<p>Can we further improve the accuracy of the KNN algorithm?</p>
</section>
<section id="use-the-trained-knn-classifier-model-to-classify-new-previously-unseen-objects">
<h4>Use the trained KNN classifier model to classify new, previously unseen objects<a class="headerlink" href="#use-the-trained-knn-classifier-model-to-classify-new-previously-unseen-objects" title="Permalink to this headline">¶</a></h4>
<p>So, here for example. We are entering the mass, width, and height for a hypothetical piece of fruit that is pretty small.</p>
<p>And if we ask the classifier to predict the label using the predict method.</p>
<p>We can see that the output says that it is a mandarin.</p>
<p>for example: a small fruit with a mass of 20 g, a width of 4.5 cm and a height of 5.2 cm</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;height&#39;, &#39;width&#39;, &#39;mass&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#sample1 = pd.DataFrame({&#39;height&#39;:[5.2], &#39;width&#39;:[4.5],&#39;mass&#39;:[20]})</span>
<span class="c1"># Notice we use the same column as the X training data (or X test sate)</span>
<span class="n">sample1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mf">5.2</span><span class="p">,</span><span class="mf">4.5</span><span class="p">,</span><span class="mi">20</span><span class="p">]],</span><span class="n">columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fruit_prediction</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sample1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The prediction is:&#39;</span><span class="p">,</span> <span class="n">lookup_fruit_name</span><span class="p">[</span><span class="n">fruit_prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The prediction is: mandarin
</pre></div>
</div>
</div>
</div>
<p>Here another example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#sample2 = pd.DataFrame({&#39;height&#39;:[6.8], &#39;width&#39;:[8.5],&#39;mass&#39;:[180]})</span>

<span class="n">sample2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mf">6.8</span><span class="p">,</span><span class="mf">8.5</span><span class="p">,</span><span class="mi">180</span><span class="p">]],</span><span class="n">columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fruit_prediction</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The prediction is:&#39;</span><span class="p">,</span> <span class="n">lookup_fruit_name</span><span class="p">[</span><span class="n">fruit_prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The prediction is: apple
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong></p>
<ol class="simple">
<li><p>Create a DataFrame comparing the y_test and the predictions from the model.</p></li>
<li><p>Confirm that the accuracy is the same as obtained by knn.score(X_test, y_test).</p></li>
</ol>
<p>Here is the list of predictions of the test set obtained from the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#fruit_prediction = knn.predict([[20,4.5,5.2]])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="calculating-the-agorithm-accuracy">
<h4>Calculating the agorithm accuracy<a class="headerlink" href="#calculating-the-agorithm-accuracy" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the accuracy of the test set</span>

<span class="c1"># https://stackoverflow.com/questions/59072143/pandas-mean-of-boolean</span>
<span class="p">((</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span><span class="o">*</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5333333333333333
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the accuracy of the original data set</span>

<span class="c1"># (knn.predict(X) == y.to_numpy()).mean()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the accuracy of the training set</span>

<span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7954545454545454
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparison-of-the-observed-and-predicted-values-from-both-training-and-test-data-sets">
<h4>Comparison of the observed and predicted values from both training and test data sets<a class="headerlink" href="#comparison-of-the-observed-and-predicted-values-from-both-training-and-test-data-sets" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Printing out the observed and predicted values of the test set</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Observed: &#39;</span><span class="p">,</span> <span class="n">lookup_fruit_name</span><span class="p">[</span><span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="s1">&#39;vs Predicted:&#39;</span><span class="p">,</span>    <span class="n">lookup_fruit_name</span><span class="p">[</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[</span><span class="n">i</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observed:  orange vs Predicted: orange
Observed:  orange vs Predicted: apple
Observed:  lemon vs Predicted: lemon
Observed:  orange vs Predicted: lemon
Observed:  apple vs Predicted: apple
Observed:  apple vs Predicted: apple
Observed:  orange vs Predicted: orange
Observed:  lemon vs Predicted: orange
Observed:  orange vs Predicted: apple
Observed:  apple vs Predicted: lemon
Observed:  mandarin vs Predicted: mandarin
Observed:  apple vs Predicted: apple
Observed:  orange vs Predicted: orange
Observed:  orange vs Predicted: apple
Observed:  orange vs Predicted: lemon
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">y_test</span><span class="o">.</span><span class="n">index</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64Index([26, 35, 43, 28, 11, 2, 34, 46, 40, 22, 4, 10, 30, 41, 33], dtype=&#39;int64&#39;)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64Index([26, 35, 43, 28, 11, 2, 34, 46, 40, 22, 4, 10, 30, 41, 33], dtype=&#39;int64&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;observed&#39;</span><span class="p">:</span> <span class="n">y_test</span> <span class="p">,</span><span class="s1">&#39;predicted&#39;</span><span class="p">:</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>observed</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>35</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>43</th>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>28</th>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>34</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>46</th>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>40</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>30</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>41</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>33</th>
      <td>3</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;observed&#39;</span><span class="p">:</span> <span class="n">y_train</span> <span class="p">,</span><span class="s1">&#39;predicted&#39;</span><span class="p">:</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>observed</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>42</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>48</th>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>32</th>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;observed&#39;</span><span class="p">:</span> <span class="n">y</span> <span class="p">,</span><span class="s1">&#39;predicted&#39;</span><span class="p">:</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>observed</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_result</span> <span class="o">=</span> <span class="n">df</span>
<span class="n">df_result</span><span class="p">[</span><span class="s1">&#39;predicted_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_result</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fruit_label</th>
      <th>fruit_name</th>
      <th>fruit_subtype</th>
      <th>mass</th>
      <th>width</th>
      <th>height</th>
      <th>color_score</th>
      <th>predicted_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>192</td>
      <td>8.4</td>
      <td>7.3</td>
      <td>0.55</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>180</td>
      <td>8.0</td>
      <td>6.8</td>
      <td>0.59</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>176</td>
      <td>7.4</td>
      <td>7.2</td>
      <td>0.60</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>86</td>
      <td>6.2</td>
      <td>4.7</td>
      <td>0.80</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>84</td>
      <td>6.0</td>
      <td>4.6</td>
      <td>0.79</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="visualize-the-decision-regions-of-a-classifier">
<h4>Visualize the decision regions of a classifier<a class="headerlink" href="#visualize-the-decision-regions-of-a-classifier" title="Permalink to this headline">¶</a></h4>
<p>After a classifier has been trained on training data, a classification model is created. What criteria does your machine learning classifier consider when deciding which class a sample belongs to? Plotting a decision region can provide some insight into the decision made by your ML classifier.</p>
<p>A <strong>decision region</strong> is a region in which a classifier predicts the same class label for data.</p>
<p>The boundary between areas of various classes is known as the <strong>decision boundary</strong>.</p>
<p>The plot decision regions function in <code class="docutils literal notranslate"><span class="pre">mlxtend</span></code> is a simple way to plot decision areas. We can also use mlxtend to plot  decision regions of <strong>Logistic Regression, Random Forest, RBF kernel SVM, and Ensemble classifier</strong>.</p>
<p><strong>Important Note</strong> for the 2D scatterplot, we can <strong>only visualize 2 features</strong> at a time. So, if you have a 3-dimensional (or more than 3) dataset, it will essentially be a <strong>2D slice through this feature space with fixed values for the remaining feature(s)</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlxtend.plotting</span> <span class="kn">import</span> <span class="n">plot_decision_regions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing a dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>  

<span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">,</span> <span class="s1">&#39;mass&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Instantiate the estimator</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Training the classifier by passing in the training set X_train and the labels in y_train</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predicting labels for unknown data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>width</th>
      <th>mass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>44.000000</td>
      <td>44.000000</td>
      <td>44.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.643182</td>
      <td>7.038636</td>
      <td>159.090909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.370350</td>
      <td>0.835886</td>
      <td>53.316876</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.000000</td>
      <td>5.800000</td>
      <td>76.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7.200000</td>
      <td>6.175000</td>
      <td>127.500000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>7.600000</td>
      <td>7.200000</td>
      <td>157.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>8.250000</td>
      <td>7.500000</td>
      <td>172.500000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.500000</td>
      <td>9.200000</td>
      <td>356.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="decision-regions-for-two-features-height-and-mass">
<h4>Decision regions for two features, height and mass.<a class="headerlink" href="#decision-regions-for-two-features-height-and-mass" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 2 = width = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">7</span>

<span class="c1"># Plot training sample with feature 2 = width = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mf">0.5</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">knn</span><span class="p">,</span>
              <span class="n">feature_index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>                        <span class="c1">#these one will be plotted  </span>
              <span class="n">filler_feature_values</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="n">value</span><span class="p">},</span>  <span class="c1">#these will be ignored</span>
              <span class="n">filler_feature_ranges</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="n">width</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (mass)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (width) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (width) = 7&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_71_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_71_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Points to be included in the plot above, </span>
<span class="c1"># i.e. those sample points with width between (value - width, value + width)</span>

<span class="c1"># X_train</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="c1">#X_train.head()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[(</span><span class="n">X_train</span><span class="o">.</span><span class="n">width</span> <span class="o">&lt;</span> <span class="n">value</span> <span class="o">+</span> <span class="n">width</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">width</span> <span class="o">&gt;</span> <span class="n">value</span> <span class="o">-</span> <span class="n">width</span><span class="p">)]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;height&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[(</span><span class="n">X_train</span><span class="o">.</span><span class="n">width</span> <span class="o">&lt;</span> <span class="n">value</span> <span class="o">+</span> <span class="n">width</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">width</span> <span class="o">&gt;</span> <span class="n">value</span> <span class="o">-</span> <span class="n">width</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    height  width  mass
9      7.0    7.4   172
32     7.0    7.2   164
12     7.1    7.0   154
19     7.2    7.4   162
42     7.2    7.2   154
37     7.3    7.3   154
21     7.4    7.4   156
29     7.4    7.0   160
39     7.4    6.8   144
36     7.6    7.1   160
13     7.7    7.3   164
8      7.8    7.1   178
38     7.8    7.2   158
45     9.2    7.2   186
47     9.7    7.3   196
48    10.1    7.3   174
44    10.5    7.3   200
42    3
48    4
32    3
29    3
37    3
8     1
13    1
38    3
12    1
45    4
36    3
21    1
19    1
9     1
39    3
47    4
44    4
Name: fruit_label, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#df.head()</span>
<span class="c1">#X_train.head()</span>
<span class="c1">#df[(df.width &lt; 7.2) &amp; (df.width &gt; 6.8)].sort_values(by = &#39;height&#39;)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="decision-regions-for-two-features-height-and-width">
<h4>Decision regions for two features, height and width.<a class="headerlink" href="#decision-regions-for-two-features-height-and-width" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#X_train.describe()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature 3 = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">30</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">knn</span><span class="p">,</span>
              <span class="n">feature_index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>               <span class="c1">#these one will be plotted  </span>
              <span class="n">filler_feature_values</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">value</span><span class="p">},</span>  <span class="c1">#these will be ignored</span>
              <span class="n">filler_feature_ranges</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">width</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (mass) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (mass) = 160&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_76_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_76_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(X_train.head())</span>
<span class="c1">#print(y_train)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##### Convert pandas DataFrame to Numpy before applying classification</span>
<span class="c1">##### </span>
<span class="c1">#### weights{‘uniform’, ‘distance’} </span>

<span class="c1">#### ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.</span>

<span class="c1">#### ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.</span>


<span class="n">X_train_np</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>


<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">100</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
              <span class="n">feature_index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>               <span class="c1">#these one will be plotted  </span>
              <span class="n">filler_feature_values</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">value</span><span class="p">},</span>  <span class="c1">#these will be ignored</span>
              <span class="n">filler_feature_ranges</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">width</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (mass) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (mass) = 160&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_78_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_78_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">)</span>
<span class="n">y_train_np</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>width</th>
      <th>mass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>44.000000</td>
      <td>44.000000</td>
      <td>44.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.643182</td>
      <td>7.038636</td>
      <td>159.090909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.370350</td>
      <td>0.835886</td>
      <td>53.316876</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.000000</td>
      <td>5.800000</td>
      <td>76.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7.200000</td>
      <td>6.175000</td>
      <td>127.500000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>7.600000</td>
      <td>7.200000</td>
      <td>157.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>8.250000</td>
      <td>7.500000</td>
      <td>172.500000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.500000</td>
      <td>9.200000</td>
      <td>356.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X_train_np = X_train.iloc[:,0:2].to_numpy()</span>
<span class="c1"># y_train_np = y_train.to_numpy()</span>

<span class="c1"># X_train_np.shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="applying-knn-classfication-with-only-two-features">
<h4>Applying KNN classfication with only two features<a class="headerlink" href="#applying-knn-classfication-with-only-two-features" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##### Convert pandas DataFrame to Numpy before applying classification</span>

<span class="n">X_train_np</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>


<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">20</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Classification problem&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Classification problem&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_82_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_82_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##### Convert pandas DataFrame to Numpy before applying classification</span>

<span class="n">X_train_np</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>


<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">20</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (mass)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Classification problem&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Classification problem&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_83_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_83_2.png" />
</div>
</div>
</section>
<section id="width-mass-visualization">
<h4>Width-Mass visualization<a class="headerlink" href="#width-mass-visualization" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(X_train.head())</span>
<span class="c1">#print(X_train.values)</span>
<span class="c1">#X_train.to_numpy()</span>

<span class="c1">#print(type(X_train.values))</span>
<span class="c1">#print(type(X_train.to_numpy()))</span>

<span class="c1">#print(X_train.values.shape)</span>
<span class="c1">#print(X_train.to_numpy().shape)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>width</th>
      <th>mass</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>44.000000</td>
      <td>44.000000</td>
      <td>44.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.643182</td>
      <td>7.038636</td>
      <td>159.090909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.370350</td>
      <td>0.835886</td>
      <td>53.316876</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.000000</td>
      <td>5.800000</td>
      <td>76.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7.200000</td>
      <td>6.175000</td>
      <td>127.500000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>7.600000</td>
      <td>7.200000</td>
      <td>157.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>8.250000</td>
      <td>7.500000</td>
      <td>172.500000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.500000</td>
      <td>9.200000</td>
      <td>356.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 1 = height = value</span>
<span class="n">value</span><span class="o">=</span><span class="mf">7.6</span>
<span class="c1"># Plot training sample with feature 1 = height = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mf">2.6</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">knn</span><span class="p">,</span>
              <span class="n">feature_index</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>               <span class="c1">#these one will be plotted  </span>
              <span class="n">filler_feature_values</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">value</span><span class="p">},</span>  <span class="c1">#these will be ignored</span>
              <span class="n">filler_feature_ranges</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">width</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (mass)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (height) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (height) = 7.6&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_87_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_87_2.png" />
</div>
</div>
</section>
<section id="width-height-visualization">
<h4>Width-height visualization<a class="headerlink" href="#width-height-visualization" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#### Applying KNN classfication with only two features</span>

<span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;width&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;width&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature 3 = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">50</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;width&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">clf</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (mass)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (height) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (height) = 160&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_90_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_90_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature 3 = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">100</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">knn</span><span class="p">,</span>
              <span class="n">feature_index</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>               <span class="c1">#these one will be plotted  </span>
              <span class="n">filler_feature_values</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">value</span><span class="p">},</span>  <span class="c1">#these will be ignored</span>
              <span class="n">filler_feature_ranges</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="n">width</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (width)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Feature 3 (mass) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Feature 3 (mass) = 160&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_91_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_91_2.png" />
</div>
</div>
</section>
<section id="visualize-from-scratch-the-decision-regions-of-a-classifier">
<h4>Visualize (from scratch) the decision regions of a classifier<a class="headerlink" href="#visualize-from-scratch-the-decision-regions-of-a-classifier" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#X = df[[&#39;height&#39;, &#39;width&#39;]].to_numpy()</span>
<span class="c1">#y = df[&#39;fruit_label&#39;].to_numpy()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The code below has been modified based on https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html</span>

<span class="c1"># we only take the first two features. We could avoid this ugly</span>
<span class="c1"># slicing by using a two-dim dataset</span>
<span class="c1">#X = iris.data[:, :2]</span>
<span class="c1">#y = iris.target</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">h</span> <span class="o">=</span> <span class="mf">0.02</span>  <span class="c1"># step size in the mesh</span>

<span class="c1"># Create color maps</span>
<span class="n">cmap_light</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;cyan&quot;</span><span class="p">,</span> <span class="s2">&quot;cornflowerblue&quot;</span><span class="p">,</span><span class="s2">&quot;green&quot;</span><span class="p">])</span>
<span class="n">cmap_bold</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;darkblue&quot;</span><span class="p">,</span><span class="s2">&quot;darkgreen&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">weights</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">]:</span>
    <span class="c1"># we create an instance of Neighbours Classifier and fit the data.</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Plot the decision boundary. For that, we will assign a color to each</span>
    <span class="c1"># point in the mesh [x_min, x_max]x[y_min, y_max].</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>

    <span class="c1"># Put the result into a color plot</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_light</span><span class="p">)</span>

    <span class="c1"># Plot also the training points</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">hue</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fruit_name</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
        <span class="n">palette</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span>
        <span class="s2">&quot;3-Class classification (k = </span><span class="si">%i</span><span class="s2">, weights = &#39;</span><span class="si">%s</span><span class="s2">&#39;)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;height&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;width&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_95_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_95_0.png" />
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_95_1.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_95_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#https://stackoverflow.com/questions/52952310/plot-decision-regions-with-error-filler-values-must-be-provided-when-x-has-more</span>
<span class="c1"># You can use PCA to reduce your data multi-dimensional data to two dimensional data. Then pass the obtained result in plot_decision_region and there will be no need of filler values.</span>

<span class="kn">from</span> <span class="nn">mlxtend.plotting</span> <span class="kn">import</span> <span class="n">plot_decision_regions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Decision region of the training set</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_97_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_97_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Decision region of the test set</span>

<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_98_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_98_2.png" />
</div>
</div>
</section>
</section>
</section>
<section id="model-evaluation-metrics-in-machine-learning">
<h2>Model Evaluation Metrics in Machine Learning<a class="headerlink" href="#model-evaluation-metrics-in-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning has become extremely popular in recent years. Machine learning is used to infer new situations from past data, and there are far too many machine learning algorithms to choose from.</p>
<p>Machine learning techniques such as</p>
<ul class="simple">
<li><p>linear regression,</p></li>
<li><p>logistic regression,</p></li>
<li><p>decision tree,</p></li>
<li><p>Naive Bayes, K-Means, and</p></li>
<li><p>Random Forest</p></li>
</ul>
<p>are widely used.</p>
<p>When it comes to predicting data, we <strong>do not use just one algorithm</strong>. Sometimes we use multiple algorithms and then proceed with the one that gives the best data predictions.</p>
<section id="how-can-we-figure-out-which-algorithm-is-the-most-effective">
<h3>How can we figure out which algorithm is the most effective?<a class="headerlink" href="#how-can-we-figure-out-which-algorithm-is-the-most-effective" title="Permalink to this headline">¶</a></h3>
<p>Model evaluation metrics allow us to evaluate the accuracy of our trained model and track its performance.</p>
<p>Model evaluation metrics, which distinguish adaptive from non-adaptive machine learning models, indicate how effectively the model generalizes to new data.</p>
<p>We could improve the overall predictive power of our model before using it for production on unknown data by using different performance evaluation metrics.</p>
<p>Choosing the right metric is very important when evaluating machine learning models. Machine learning models are evaluated using a variety of metrics in different applications. Let us look at the metrics for evaluating the performance of a machine learning model.</p>
<p>This is a critical phase in any data science project as it aims to estimate the generalization accuracy of a model for future data.</p>
<p><strong>Evaluation Metrics For Regression Models</strong>: image from enjoyalgorithms
<img alt="Evaluation Metrics For Regression Models from enjoyalgorithms" src="https://www.enjoyalgorithms.com/static/evaluation-metrics-regression-models-cover-6422d3e49173675d75d121740c04d450.jpg" /></p>
<p><strong>Evaluation Metrics For Classification Models</strong>: image from enjoyalgorithms
<img alt="Evaluation Metrics For Classification Models from enjoyalgorithms" src="https://www.enjoyalgorithms.com/static/evaluation-metrics-classification-models-cover-4f403c2e47e719b4389b4b2d05d71c34.jpg" /></p>
<section id="regression-related-metrics">
<h4>Regression Related Metrics<a class="headerlink" href="#regression-related-metrics" title="Permalink to this headline">¶</a></h4>
<p>The most common measures for evaluating a regression model (as used in our previous chapter) are:</p>
<ul class="simple">
<li><p><strong>Mean Absolute Error (MAE)</strong>: The average of the difference between the actual and anticipated values is the Mean Absolute Error. It determines how close the predictions are to the actual results. The better the model, the lower the MAE.</p></li>
<li><p><strong>Mean Squared Error (MSE)</strong>: The average of the square of the difference between the actual and predicted values is calculated by MSE.</p></li>
<li><p><strong>R2 score</strong>: The proportion of variance in Y that can be explained by X is called the R2 score.</p></li>
</ul>
</section>
<section id="classification-metrics">
<h4>Classification Metrics<a class="headerlink" href="#classification-metrics" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p><strong>Confusion Matrix (Accuracy, Sensitivity, and Specificity)</strong></p></li>
</ol>
<p>A confusion matrix contains the results of any binary testing that is commonly used to describe the classification model’s performance.</p>
<p>In a binary classification task, there are only two classes to categorize, preferably a <strong>positive class</strong> and a <strong>negative class</strong>.</p>
<p>Let us take a look at the metrics of the confusion matrix.</p>
<ul class="simple">
<li><p><strong>Accuracy</strong>: indicates the overall accuracy of the model, i.e., the percentage of all samples that were correctly identified by the classifier. Use the following formula to calculate accuracy:
(TP +TN)/(TP +TN+ FP +FN).</p>
<ul>
<li><p>True Positive (TP): This is the number of times the classifier successfully predicted the positive class to be positive.</p></li>
<li><p>True Negative (TN): The number of times the classifier correctly predicts the negative class as negative.</p></li>
<li><p>False Positive (FP): This term refers to the number of times a classifier incorrectly predicts a negative class as positive.</p></li>
<li><p>False Negative (FN): This is the number of times the classifier predicts the positive class as negative.</p></li>
</ul>
</li>
<li><p><strong>The misclassification rate</strong>: tells you what percentage of predictions were incorrect. It is also called classification error. You can calculate it with (FP +FN)/(TP +TN+ FP +FN) or (1-accuracy).</p></li>
<li><p><strong>Sensitivity (or Recall)</strong>: It indicates the proportion of all positive samples that were correctly predicted to be positive by the classifier. It is also referred to as <strong>true positive rate (TPR), sensitivity, or probability of detection</strong>. To calculate recall, use the following formula: TP /(TP +FN).</p></li>
<li><p><strong>Specificity</strong>: it indicates the proportion of all negative samples that are correctly predicted to be negative by the classifier. It is also referred to as the <strong>True Negative Rate (TNR)</strong>. To calculate the specificity, use the following formula: TN /(TN +FP).</p></li>
</ul>
<ol class="simple">
<li><p><strong>Precision</strong>: When there is an <strong>imbalance between classes</strong>, accuracy can become an unreliable metric for measuring our performance. Therefore, we also need to address class-specific performance metrics. Precision is one such metric, defined as <strong>positive predictive values</strong> (Proportion of predictions as positive class were actually positive). To calculate precision, use the following formula: TP/(TP+FP).</p></li>
<li><p><strong>F1-score</strong>: it combines precision and recall in a single measure. Mathematically, it is the harmonic mean of Precision and Recall. It can be calculated as follows:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[{\displaystyle F_{1}={\frac {2}{\mathrm {recall^{-1}} +\mathrm {precision^{-1}} }}=2\cdot {\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}={\frac {\mathrm {tp} }{\mathrm {tp} +{\frac {1}{2}}(\mathrm {fp} +\mathrm {fn} )}}}.\]</div>
<p>In a perfect world, we would want a model that has a precision of 1 and a recall of 1. This means an F1 score of 1, i.e. 100% accuracy, which is often not the case for a machine learning model. So we should try to achieve a higher precision with a higher recall value.</p>
<p><strong>Confusion Matrix for Binary Classification</strong>: image from <a class="reference external" href="https://towardsdatascience.com/">https://towardsdatascience.com/</a>
<img alt="Confusion Matrix for Binary Classification image from https://towardsdatascience.com/" src="https://miro.medium.com/max/700/1*fxiTNIgOyvAombPJx5KGeA.png" /></p>
<p><strong>Confusion Matrix for Multi-class Classification</strong>: image from <a class="reference external" href="https://towardsdatascience.com/">https://towardsdatascience.com/</a>
<img alt="Confusion Matrix for Multi-class Classification image from https://towardsdatascience.com/" src="https://miro.medium.com/max/700/1*yH2SM0DIUQlEiveK42NnBg.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing a dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>  

<span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">,</span> <span class="s1">&#39;mass&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Instantiate the estimator</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Training the classifier by passing in the training set X_train and the labels in y_train</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predicting labels for unknown data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#importing confusion matrix</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span>
<span class="n">confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix

[[3 0 0 1]
 [0 1 0 0]
 [3 0 3 2]
 [0 0 1 1]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Confusion Matrix visualization.</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">knn</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span><span class="n">display_labels</span><span class="o">=</span><span class="n">knn</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1245dee90&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_109_1.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_109_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;observed&#39;</span><span class="p">:</span> <span class="n">y_test</span> <span class="p">,</span><span class="s1">&#39;predicted&#39;</span><span class="p">:</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;observed&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>observed</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>11</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>26</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>35</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>28</th>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>34</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>40</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>30</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>41</th>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>33</th>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>43</th>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>46</th>
      <td>4</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Unlike the binary classification, there are no positive or negative classes here.</p>
<p>At first glance, it might be a little difficult to find TP, TN, FP, and FN since there are no positive or negative classes, but it’s actually pretty simple.</p>
<p>What we need to do here is find TP, TN, FP and FN for each and every class. For example, let us take the <strong>Apple class</strong>. Let us look at what values the metrics have in the confusion matrix.
(DO NOT FORGET TO TRANSPOSE)</p>
<ul class="simple">
<li><p>TP = 3</p></li>
<li><p>TN = (1 + 3 + 2 + 1 + 1) = 8 (the sum of the numbers in rows 2-4 and columns 2-4)</p></li>
<li><p>FP = (0 + 3 + 0) = 3</p></li>
<li><p>FN = (0 + 0 + 1) = 1</p></li>
</ul>
<p>Now that we have all the necessary metrics for the Apple class from the confusion matrix, we can calculate the performance metrics for the Apple class. For example, the class Apple has</p>
<ul class="simple">
<li><p>Precision = 3/(3+3) = 0.5</p></li>
<li><p>Recall = 3/(3+1) = 0.75</p></li>
<li><p>F1-score = 0.60</p></li>
</ul>
<p>In a similar way, we can calculate the measures for the other classes. Here is a table showing the values of each measure for each class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Classification Report</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 3&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 4&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification Report

              precision    recall  f1-score   support

     Class 1       0.50      0.75      0.60         4
     Class 2       1.00      1.00      1.00         1
     Class 3       0.75      0.38      0.50         8
     Class 4       0.25      0.50      0.33         2

    accuracy                           0.53        15
   macro avg       0.62      0.66      0.61        15
weighted avg       0.63      0.53      0.54        15
</pre></div>
</div>
</div>
</div>
<p>Now we can do more with these measures. We can combine the F1 score of each class to get a single measure for the entire model. There are several ways to do this, which we will now look at.</p>
<ul class="simple">
<li><p><strong>Macro F1</strong>
This is the macro-averaged F1 score. It calculates the metrics for each class separately and then takes the unweighted average of the measures. As we saw in the figure “Precision, recall and F1 score for each class”,</p></li>
<li><p><strong>Weighted F1</strong>
The final value is the weighted mean F1 score. Unlike Macro F1, this uses a weighted mean of the measures. The weights for each class are the total number of samples in that class. Since we had 4 apples, 1 mandarin, 8 oranges, and 3 lemons,</p></li>
</ul>
<p>We obtain a classficiation rate of 53.3%, considered as good accuracy.</p>
<p>Can we further improve the accuracy of the KNN algorithm?</p>
<p>In our example, we have created an instance (‘knn’) of the class ‘KNeighborsClassifer,’ which means we have constructed an object called ‘knn’ that knows how to perform KNN classification once the data is provided.</p>
<p>The tuning parameter/hyper parameter (K) is the parameter <strong>n_neighbors</strong>. All other parameters are set to default values.</p>
<p><strong>Exercises</strong></p>
<ol class="simple">
<li><p>Fit the model and test it for different values for K (from 1 to 5) using a for loop and record the KNN’s testing accuracy of the KNN in a variable.</p></li>
<li><p>Plot the relationship between the values of K and the corresponding testing accuracy.</p></li>
<li><p>Select the optimal value of K that gives the highest testing accuray.</p></li>
<li><p>Compare the results between the optimal value of K and K = 5.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing a dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>  

<span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">,</span> <span class="s1">&#39;mass&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Instantiate the estimator</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>

<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>

<span class="n">train_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">test_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="c1"># Training the classifier by passing in the training set X_train and the labels in y_train</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Compute accuracy on the training set</span>
    <span class="n">train_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    
    
    <span class="n">test_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">test_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_output</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;k&#39;</span><span class="p">:</span><span class="n">k_range</span><span class="p">,</span>
                          <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span><span class="n">train_accuracy_list</span><span class="p">,</span>
                          <span class="s1">&#39;test_accuracy&#39;</span><span class="p">:</span><span class="n">test_accuracy_list</span>
                         <span class="p">})</span>

<span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">df_output</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;training accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;test_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;testing accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;k (n_neighbors)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;overall accuracy&#39;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">],</span> <span class="c1"># Colors</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_117_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_117_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (309453589)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
<span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.872983346207417
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">hm</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">hm</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Correlation matrix of insurance data</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_119_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_119_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">,</span><span class="s1">&#39;color_score&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]],</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;fruit_name&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x126f633d0&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_120_1.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_120_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing a dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>  

<span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;color_score&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Instantiate the estimator</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>

<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>

<span class="n">train_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">test_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="c1"># Training the classifier by passing in the training set X_train and the labels in y_train</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Compute accuracy on the training set</span>
    <span class="n">train_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    
    
    <span class="n">test_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">test_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_output</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;k&#39;</span><span class="p">:</span><span class="n">k_range</span><span class="p">,</span>
                          <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span><span class="n">train_accuracy_list</span><span class="p">,</span>
                          <span class="s1">&#39;test_accuracy&#39;</span><span class="p">:</span><span class="n">test_accuracy_list</span>
                         <span class="p">})</span>

<span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">df_output</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;training accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;test_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;testing accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;k (n_neighbors)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;overall accuracy&#39;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">],</span> <span class="c1"># Colors</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_122_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_122_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (309631441)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##### Convert pandas DataFrame to Numpy before applying classification</span>

<span class="n">X_train_np</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">X_test_np</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_test_np</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">20</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (color_scale)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Classification problem&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Kaemyuijang/opt/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:279: UserWarning: You passed a edgecolor/edgecolors (&#39;black&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Classification problem&#39;)
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_123_2.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_123_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span> <span class="mf">8.5</span> <span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">9.2</span> <span class="p">,</span>  <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([4, 3])
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="scaling">
<h2>Scaling<a class="headerlink" href="#scaling" title="Permalink to this headline">¶</a></h2>
<p>Because KNN uses the Euclidean distance between points to determine the closest neighboring points, all of the data must be on the same scale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fruit_label</th>
      <th>fruit_name</th>
      <th>fruit_subtype</th>
      <th>mass</th>
      <th>width</th>
      <th>height</th>
      <th>color_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>192</td>
      <td>8.4</td>
      <td>7.3</td>
      <td>0.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>180</td>
      <td>8.0</td>
      <td>6.8</td>
      <td>0.59</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>apple</td>
      <td>granny_smith</td>
      <td>176</td>
      <td>7.4</td>
      <td>7.2</td>
      <td>0.60</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>86</td>
      <td>6.2</td>
      <td>4.7</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>mandarin</td>
      <td>mandarin</td>
      <td>84</td>
      <td>6.0</td>
      <td>4.6</td>
      <td>0.79</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#df[[&#39;mass&#39;,&#39;width&#39;,&#39;height&#39;,&#39;color_score&#39;]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;mass&#39;</span><span class="p">,</span><span class="s1">&#39;width&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">,</span><span class="s1">&#39;color_score&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="n">scaled_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
                        <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mass</th>
      <th>width</th>
      <th>height</th>
      <th>color_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.405594</td>
      <td>0.684211</td>
      <td>0.507692</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.363636</td>
      <td>0.578947</td>
      <td>0.430769</td>
      <td>0.105263</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.349650</td>
      <td>0.421053</td>
      <td>0.492308</td>
      <td>0.131579</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.034965</td>
      <td>0.105263</td>
      <td>0.107692</td>
      <td>0.657895</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.027972</td>
      <td>0.052632</td>
      <td>0.092308</td>
      <td>0.631579</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_df</span> <span class="o">=</span> <span class="n">scaled_X</span>
<span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]]</span>
<span class="c1">#scaled_df</span>

<span class="n">hm</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scaled_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">hm</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Correlation matrix of insurance data</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_131_0.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_131_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">scaled_df</span><span class="p">[[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">,</span><span class="s1">&#39;color_score&#39;</span><span class="p">,</span><span class="s1">&#39;height&#39;</span><span class="p">]],</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x12578d850&gt;
</pre></div>
</div>
<img alt="_images/Chapter7_Introduction_Machine_Learning-Copy1_132_1.png" src="_images/Chapter7_Introduction_Machine_Learning-Copy1_132_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing a dataset</span>
<span class="c1">#url = &#39;https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/fruit_data_with_colors.txt&#39;</span>
<span class="c1">#df = pd.read_table(url)  </span>

<span class="c1"># Train Test Split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;color_score&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;fruit_label&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Instantiate the estimator</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>

<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>

<span class="n">train_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">test_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="c1"># Training the classifier by passing in the training set X_train and the labels in y_train</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Compute accuracy on the training set</span>
    <span class="n">train_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    
    
    <span class="n">test_accuracy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">test_accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{1: 0.8666666666666667, 2: 0.8666666666666667, 3: 0.8666666666666667, 4: 0.8666666666666667, 5: 0.8666666666666667, 6: 0.8666666666666667, 7: 0.8, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 0.6666666666666666}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_df_output</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">var</span><span class="o">/</span><span class="n">folders</span><span class="o">/</span><span class="n">kl</span><span class="o">/</span><span class="n">h_r05n_j76n32kt0dwy7kynw0000gn</span><span class="o">/</span><span class="n">T</span><span class="o">/</span><span class="n">ipykernel_1141</span><span class="o">/</span><span class="mf">859115368.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">scaled_df_output</span>

<span class="ne">NameError</span>: name &#39;scaled_df_output&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_df_output</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;k&#39;</span><span class="p">:</span><span class="n">k_range</span><span class="p">,</span>
                          <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span><span class="n">train_accuracy_list</span><span class="p">,</span>
                          <span class="s1">&#39;test_accuracy&#39;</span><span class="p">:</span><span class="n">test_accuracy_list</span>
                         <span class="p">})</span>

<span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">scaled_df_output</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;training accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>  <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;test_accuracy&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;&quot;testing accuracy&quot;&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;k (n_neighbors)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;overall accuracy&#39;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">],</span> <span class="c1"># Colors</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##### Convert pandas DataFrame to Numpy before applying classification</span>

<span class="n">X_train_np</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train_np</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">X_test_np</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_test_np</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_np</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">)</span>

<span class="c1"># Plotting decision regions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Decision region for feature 3 = mass = value</span>
<span class="n">value</span><span class="o">=</span><span class="mi">160</span>
<span class="c1"># Plot training sample with feature = mass = value +/- width</span>
<span class="n">width</span><span class="o">=</span><span class="mi">20</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1 (height)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2 (color_scale)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Classification problem&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_accuracy</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pairote Satiracoo<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>